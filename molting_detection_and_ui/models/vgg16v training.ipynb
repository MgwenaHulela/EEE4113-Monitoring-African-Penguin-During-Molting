# === IMPORTS ===
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import models, transforms, datasets
from torch.utils.data import DataLoader, Subset
from sklearn.model_selection import KFold
from sklearn.metrics import (classification_report, confusion_matrix, roc_curve,
                             auc, precision_recall_curve)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# === CONFIG ===
SAVE_DIR = './checkpoints'
os.makedirs(SAVE_DIR, exist_ok=True)
EPOCHS = 10
PATIENCE = 3
K = 5
BATCH_SIZE = 32
NUM_WORKERS = 2
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print(f"‚úÖ Using device: {DEVICE}")

# === COPY DATASET LOCALLY FOR FASTER ACCESS ===
LOCAL_DATASET_PATH = '/content/dataset_copy'
if not os.path.exists(LOCAL_DATASET_PATH):
    print("üìÇ Copying dataset from Google Drive to local disk for faster access...")
    !cp -r "/content/drive/MyDrive/Colab Notebooks/cnn_validation_train" {LOCAL_DATASET_PATH}
    print("‚úÖ Dataset copied.")
DATASET_ROOT = LOCAL_DATASET_PATH

# === TRANSFORM & DATASET ===
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
dataset = datasets.ImageFolder(root=DATASET_ROOT, transform=transform)
num_classes = len(dataset.classes)

# === OPTIONAL: Use smaller dataset to debug faster ===
USE_SMALL_SUBSET = False  # Set to True if you want fast debugging first
if USE_SMALL_SUBSET:
    dataset = Subset(dataset, range(0, 500))
    print(f"‚ö†Ô∏è Using small debug dataset with {len(dataset)} images")

# === MODEL DEFINITION ===
def get_vgg_model():
    model = models.vgg16(pretrained=True)
    for param in model.parameters():
        param.requires_grad = False
    model.classifier[6] = nn.Linear(4096, num_classes)
    return model

# === PLOTTING FUNCTIONS ===
def plot_training_curves(history, fold, save_dir):
    epochs = range(1, len(history['train_loss']) + 1)
    plt.figure()
    plt.plot(epochs, history['train_loss'], label='Train Loss')
    plt.plot(epochs, history['val_loss'], label='Val Loss')
    plt.title(f'Loss Curve (Fold {fold})')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig(os.path.join(save_dir, f'loss_curve_fold{fold}.png'))
    plt.close()

    plt.figure()
    plt.plot(epochs, history['train_acc'], label='Train Acc')
    plt.plot(epochs, history['val_acc'], label='Val Acc')
    plt.title(f'Accuracy Curve (Fold {fold})')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.savefig(os.path.join(save_dir, f'acc_curve_fold{fold}.png'))
    plt.close()

def plot_roc_pr_curves(y_true, y_scores, fold, save_dir):
    y_true = np.array(y_true)
    y_scores = np.array(y_scores)

    for class_idx in range(num_classes):
        fpr, tpr, _ = roc_curve(y_true == class_idx, y_scores[:, class_idx])
        roc_auc = auc(fpr, tpr)
        plt.figure()
        plt.plot(fpr, tpr, label=f'Class {dataset.classes[class_idx]} (AUC = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], 'k--')
        plt.title(f'ROC Curve (Class {dataset.classes[class_idx]}, Fold {fold})')
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.legend()
        plt.savefig(os.path.join(save_dir, f'roc_curve_fold{fold}_class{class_idx}.png'))
        plt.close()

        precision, recall, _ = precision_recall_curve(y_true == class_idx, y_scores[:, class_idx])
        plt.figure()
        plt.plot(recall, precision, label=f'Class {dataset.classes[class_idx]}')
        plt.title(f'PR Curve (Class {dataset.classes[class_idx]}, Fold {fold})')
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.legend()
        plt.savefig(os.path.join(save_dir, f'pr_curve_fold{fold}_class{class_idx}.png'))
        plt.close()

# === TRAINING ===
def train_model(model, train_loader, val_loader, optimizer, loss_fn, epochs, patience, device, fold):
    best_val_loss = float('inf')
    early_stop_counter = 0
    best_model_path = os.path.join(SAVE_DIR, f'best_model_fold{fold}.pt')
    last_model_path = os.path.join(SAVE_DIR, f'last_model_fold{fold}.pt')

    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}

    for epoch in range(epochs):
        model.train()
        running_loss, correct, total = 0.0, 0, 0
        loop = tqdm(train_loader, desc=f"üöÄ Training Fold {fold+1} Epoch {epoch+1}", leave=False)
        for inputs, labels in loop:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = loss_fn(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

        train_loss = running_loss / len(train_loader)
        train_acc = correct / total

        model.eval()
        val_loss, val_correct, val_total = 0.0, 0, 0
        val_loop = tqdm(val_loader, desc=f"üîç Validating Fold {fold+1} Epoch {epoch+1}", leave=False)
        with torch.no_grad():
            for inputs, labels in val_loop:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = loss_fn(outputs, labels)
                val_loss += loss.item()
                _, preds = torch.max(outputs, 1)
                val_correct += (preds == labels).sum().item()
                val_total += labels.size(0)

        val_loss /= len(val_loader)
        val_acc = val_correct / val_total

        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['train_acc'].append(train_acc)
        history['val_acc'].append(val_acc)

        print(f"üìä Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}% | "
              f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%")

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            early_stop_counter = 0
            torch.save(model.state_dict(), best_model_path)
        else:
            early_stop_counter += 1
            if early_stop_counter >= patience:
                print(f"‚èπÔ∏è Early stopping at epoch {epoch+1}")
                break

    torch.save(model.state_dict(), last_model_path)
    plot_training_curves(history, fold, SAVE_DIR)
    return model, history

# === EVALUATION ===
def evaluate_model(model, val_loader, device='cuda'):
    model.to(device)
    model.eval()
    y_true, y_pred, y_scores = [], [], []
    with torch.no_grad():
        for inputs, labels in tqdm(val_loader, desc="üîç Evaluating...", leave=False):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(predicted.cpu().numpy())
            y_scores.extend(torch.softmax(outputs, dim=1).cpu().numpy())

    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)
    matrix = confusion_matrix(y_true, y_pred)
    return report, matrix, y_true, y_scores

# === MAIN LOOP ===
def k_fold_cross_validation_vgg(dataset, k=5, epochs=10, batch_size=32, device='cuda'):
    kfold = KFold(n_splits=k, shuffle=True)
    summary_records = []

    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):
        print(f"\n==== Fold {fold+1}/{k} ====")
        train_loader = DataLoader(Subset(dataset, train_idx), batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS)
        val_loader = DataLoader(Subset(dataset, val_idx), batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS)

        model = get_vgg_model().to(device)
        optimizer = optim.Adam(model.classifier.parameters(), lr=1e-4)
        loss_fn = nn.CrossEntropyLoss()

        model, history = train_model(model, train_loader, val_loader, optimizer, loss_fn,
                                     epochs, PATIENCE, device, fold)

        report, matrix, y_true, y_scores = evaluate_model(model, val_loader, device)

        acc = report['accuracy']
        summary_records.append({
            'fold': fold + 1,
            'accuracy': acc,
            'precision_macro': report['macro avg']['precision'],
            'recall_macro': report['macro avg']['recall'],
            'f1_macro': report['macro avg']['f1-score']
        })

        df_report = pd.DataFrame(report).transpose()
        df_report.to_csv(os.path.join(SAVE_DIR, f'class_report_fold{fold}.csv'))

        sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues',
                    xticklabels=dataset.classes, yticklabels=dataset.classes)
        plt.title(f'Confusion Matrix (Fold {fold+1})')
        plt.xlabel('Predicted')
        plt.ylabel('True')
        plt.savefig(os.path.join(SAVE_DIR, f'confusion_matrix_fold{fold}.png'))
        plt.close()

        plot_roc_pr_curves(y_true, y_scores, fold, SAVE_DIR)

        print(f"‚úÖ Fold {fold+1} Accuracy: {acc*100:.2f}%")

    # Save summary across all folds
    df_summary = pd.DataFrame(summary_records)
    df_summary.loc['Average'] = df_summary.mean(numeric_only=True)
    df_summary.to_csv(os.path.join(SAVE_DIR, 'summary_across_folds.csv'), index=False)

    print("\n==== Summary saved to summary_across_folds.csv ====")

# === RUN ===
k_fold_cross_validation_vgg(dataset, k=K, epochs=EPOCHS, batch_size=BATCH_SIZE, device=DEVICE)
